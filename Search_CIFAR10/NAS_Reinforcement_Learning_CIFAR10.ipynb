{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),  # CIFAR-10 mean\n",
    "                         (0.2023, 0.1994, 0.2010))  # CIFAR-10 std\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "full_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Reduce dataset size to simulate limited data\n",
    "small_dataset_size = 5000  # Use only 5,000 samples\n",
    "indices = list(range(len(full_dataset)))\n",
    "random.shuffle(indices)\n",
    "small_indices = indices[:small_dataset_size]\n",
    "small_dataset = torch.utils.data.Subset(full_dataset, small_indices)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(small_dataset))\n",
    "val_size = len(small_dataset) - train_size\n",
    "train_subset, val_subset = random_split(small_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Define the Controller Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, num_operations, num_filters):\n",
    "        super(Controller, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_operations = num_operations\n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        self.rnn = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.op_linear = nn.Linear(hidden_size, num_operations)\n",
    "        self.filter_linear = nn.Linear(hidden_size, num_filters)\n",
    "        self.num_embeddings = self.num_operations * self.num_filters\n",
    "        print(f\"Initializing embedding layer with num_embeddings = {self.num_embeddings}\")\n",
    "        self.embedding = nn.Embedding(self.num_embeddings, hidden_size)\n",
    "\n",
    "    def forward(self, hidden, cell, inputs):\n",
    "        hx, cx = self.rnn(inputs, (hidden, cell))\n",
    "        op_logits = self.op_linear(hx)\n",
    "        filter_logits = self.filter_linear(hx)\n",
    "        return op_logits, filter_logits, hx, cx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Define the Child Network Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Possible operations with varying output channels\n",
    "OPERATIONS = [\n",
    "    ('conv3x3', 16),\n",
    "    ('conv3x3', 32),\n",
    "    ('conv5x5', 16),\n",
    "    ('conv5x5', 32),\n",
    "    ('maxpool3x3', None)\n",
    "]\n",
    "\n",
    "def construct_network(architecture):\n",
    "    layers = []\n",
    "    input_channels = 3\n",
    "    current_channels = input_channels\n",
    "    max_num_layers = 3  # Limit the number of layers\n",
    "    for idx, (op_idx, filter_size_idx) in enumerate(architecture):\n",
    "        if idx >= max_num_layers:\n",
    "            break\n",
    "        op_name = OPERATIONS[op_idx]\n",
    "        out_channels = FILTER_SIZES[filter_size_idx]\n",
    "        if op_name == 'conv3x3':\n",
    "            layers.append(nn.Conv2d(current_channels, out_channels, kernel_size=3, padding=1))\n",
    "            current_channels = out_channels\n",
    "        elif op_name == 'conv5x5':\n",
    "            layers.append(nn.Conv2d(current_channels, out_channels, kernel_size=5, padding=2))\n",
    "            current_channels = out_channels\n",
    "        elif op_name == 'maxpool3x3':\n",
    "            layers.append(nn.MaxPool2d(kernel_size=3, stride=1, padding=1))\n",
    "            # current_channels remains the same\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.AdaptiveAvgPool2d(1))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(current_channels, 10))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def train_child_network(network, epochs=1):\n",
    "    network.train()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    max_batches = 10  # Limit to 10 batches per epoch\n",
    "    for epoch in range(epochs):\n",
    "        batch_count = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_count += 1\n",
    "            if batch_count >= max_batches:\n",
    "                break  # Stop after processing max_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5: Define the Reinforcement Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(controller, controller_optimizer, num_layers, num_operations, num_filters, num_samples):\n",
    "    controller.train()\n",
    "    all_rewards = []\n",
    "    for sample in range(num_samples):\n",
    "        hidden = torch.zeros(1, controller.hidden_size)\n",
    "        cell = torch.zeros(1, controller.hidden_size)\n",
    "        inputs = torch.zeros(1, controller.hidden_size)\n",
    "        architecture = []\n",
    "        log_probs = []\n",
    "        for _ in range(num_layers):\n",
    "            op_logits, filter_logits, hidden, cell = controller(hidden, cell, inputs)\n",
    "            op_probs = F.softmax(op_logits, dim=-1)\n",
    "            filter_probs = F.softmax(filter_logits, dim=-1)\n",
    "            op_dist = torch.distributions.Categorical(op_probs)\n",
    "            filter_dist = torch.distributions.Categorical(filter_probs)\n",
    "            op = op_dist.sample().long()\n",
    "            filter_size = filter_dist.sample().long()\n",
    "            embedding_index = op * controller.num_filters + filter_size\n",
    "            # Print statements for debugging\n",
    "            print(f\"op: {op.item()}, filter_size: {filter_size.item()}\")\n",
    "            print(f\"embedding_index: {embedding_index.item()}, max index: {controller.num_operations * controller.num_filters - 1}\")\n",
    "            # Ensure embedding_index is within bounds\n",
    "            if embedding_index.item() >= controller.num_operations * controller.num_filters:\n",
    "                raise ValueError(f\"embedding_index {embedding_index.item()} out of bounds\")\n",
    "            inputs = controller.embedding(embedding_index)\n",
    "            architecture.append((op.item(), filter_size.item()))\n",
    "            log_probs.append(op_dist.log_prob(op) + filter_dist.log_prob(filter_size))\n",
    "        # ... rest of the code ...\n",
    "\n",
    "        try:\n",
    "            network = construct_network(architecture)\n",
    "            train_child_network(network, epochs=1)\n",
    "            # Evaluate on validation data\n",
    "            network.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in val_loader:\n",
    "                    output = network(data)\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "            reward = correct / total\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred: {e}\")\n",
    "            reward = 0.0\n",
    "        all_rewards.append(reward)\n",
    "        # Policy gradient update\n",
    "        loss = -sum(log_probs) * reward\n",
    "        controller_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        controller_optimizer.step()\n",
    "    return all_rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: Train the Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with num_embeddings = 9\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "Epoch 1/10, Average Reward: 0.1216, Time: 18.77s\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "Epoch 2/10, Average Reward: 0.1130, Time: 19.92s\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     15\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 16\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m \u001b[43mreinforce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontroller_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     avg_reward \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(rewards)\n\u001b[0;32m     18\u001b[0m     rewards_per_epoch\u001b[38;5;241m.\u001b[39mappend(avg_reward)\n",
      "Cell \u001b[1;32mIn[12], line 39\u001b[0m, in \u001b[0;36mreinforce\u001b[1;34m(controller, controller_optimizer, num_layers, num_operations, num_filters, num_samples)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m---> 39\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\grudk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\grudk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\grudk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\grudk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\grudk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\grudk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\grudk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 35\n",
    "num_layers = 5\n",
    "OPERATIONS = ['conv3x3', 'conv5x5', 'maxpool3x3']\n",
    "FILTER_SIZES = [16, 32, 64]\n",
    "num_operations = len(OPERATIONS)\n",
    "num_filters = len(FILTER_SIZES)\n",
    "controller = Controller(hidden_size, num_layers, num_operations, num_filters)\n",
    "controller_optimizer = optim.Adam(controller.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "rewards_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    rewards = reinforce(controller, controller_optimizer, num_layers, num_operations, num_filters, num_samples=5)\n",
    "    avg_reward = np.mean(rewards)\n",
    "    rewards_per_epoch.append(avg_reward)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Reward: {avg_reward:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Plotting rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), rewards_per_epoch, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Reward (Validation Accuracy)')\n",
    "plt.title('Controller Training Progress')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7: Evaluate the Best Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     embedding_index \u001b[38;5;241m=\u001b[39m op \u001b[38;5;241m*\u001b[39m controller\u001b[38;5;241m.\u001b[39mnum_filters \u001b[38;5;241m+\u001b[39m filter_size\n\u001b[0;32m     13\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m controller\u001b[38;5;241m.\u001b[39membedding(embedding_index)\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Architecture:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[43mOPERATIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mop\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m architecture])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Construct and train the best network\u001b[39;00m\n\u001b[0;32m     19\u001b[0m best_network \u001b[38;5;241m=\u001b[39m construct_network(architecture)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "controller.eval()\n",
    "hidden = torch.zeros(1, controller.hidden_size)\n",
    "cell = torch.zeros(1, controller.hidden_size)\n",
    "inputs = torch.zeros(1, controller.hidden_size)  # Corrected initialization\n",
    "architecture = []\n",
    "for _ in range(num_layers):\n",
    "    op_logits, filter_logits, hidden, cell = controller(hidden, cell, inputs)\n",
    "    op = torch.argmax(op_logits, dim=-1)\n",
    "    filter_size = torch.argmax(filter_logits, dim=-1)\n",
    "    architecture.append((op.item(), filter_size.item()))\n",
    "    # Compute the embedding index\n",
    "    embedding_index = op * controller.num_filters + filter_size\n",
    "    inputs = controller.embedding(embedding_index)\n",
    "\n",
    "\n",
    "print(\"Best Architecture:\", [OPERATIONS[op] for op in architecture])\n",
    "\n",
    "# Construct and train the best network\n",
    "best_network = construct_network(architecture)\n",
    "train_child_network(best_network, epochs=5)\n",
    "\n",
    "# Evaluate on test data\n",
    "best_network.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = best_network(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy of Best Architecture: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 8: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Placeholder for visualization code, such as plotting rewards over epochs.\n",
    "# In this simplified implementation, we only printed average rewards per epoch.\n",
    "\n",
    "# For example, you might have collected rewards per epoch and can plot them:\n",
    "rewards_per_epoch = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    rewards = reinforce(controller, controller_optimizer, num_layers, num_operations, num_samples=1)\n",
    "    avg_reward = np.mean(rewards)\n",
    "    rewards_per_epoch.append(avg_reward)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Reward: {avg_reward:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Plot the rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs+1), rewards_per_epoch, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Reward (Validation Accuracy)')\n",
    "plt.title('Rewards over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
