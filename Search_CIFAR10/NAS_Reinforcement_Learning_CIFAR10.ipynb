{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),  # CIFAR-10 mean\n",
    "                         (0.2023, 0.1994, 0.2010))  # CIFAR-10 std\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "full_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Reduce dataset size to simulate limited data\n",
    "small_dataset_size = 5000  # Use only 5,000 samples\n",
    "indices = list(range(len(full_dataset)))\n",
    "random.shuffle(indices)\n",
    "small_indices = indices[:small_dataset_size]\n",
    "small_dataset = torch.utils.data.Subset(full_dataset, small_indices)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(small_dataset))\n",
    "val_size = len(small_dataset) - train_size\n",
    "train_subset, val_subset = random_split(small_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Define the Controller Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, num_operations, num_filters):\n",
    "        super(Controller, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_operations = num_operations\n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        self.rnn = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.op_linear = nn.Linear(hidden_size, num_operations)\n",
    "        self.filter_linear = nn.Linear(hidden_size, num_filters)\n",
    "        self.num_embeddings = self.num_operations * self.num_filters\n",
    "        print(f\"Initializing embedding layer with num_embeddings = {self.num_embeddings}\")\n",
    "        self.embedding = nn.Embedding(self.num_embeddings, hidden_size)\n",
    "\n",
    "    def forward(self, hidden, cell, inputs):\n",
    "        hx, cx = self.rnn(inputs, (hidden, cell))\n",
    "        op_logits = self.op_linear(hx)\n",
    "        filter_logits = self.filter_linear(hx)\n",
    "        return op_logits, filter_logits, hx, cx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Define the Child Network Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Possible operations with varying output channels\n",
    "OPERATIONS = [\n",
    "    ('conv3x3', 16),\n",
    "    ('conv3x3', 32),\n",
    "    ('conv5x5', 16),\n",
    "    ('conv5x5', 32),\n",
    "    ('maxpool3x3', None)\n",
    "]\n",
    "\n",
    "def construct_network(architecture):\n",
    "    layers = []\n",
    "    input_channels = 3\n",
    "    current_channels = input_channels\n",
    "    max_num_layers = 3  # Limit the number of layers\n",
    "    for idx, (op_idx, filter_size_idx) in enumerate(architecture):\n",
    "        if idx >= max_num_layers:\n",
    "            break\n",
    "        op_name = OPERATIONS[op_idx]\n",
    "        out_channels = FILTER_SIZES[filter_size_idx]\n",
    "        if op_name == 'conv3x3':\n",
    "            layers.append(nn.Conv2d(current_channels, out_channels, kernel_size=3, padding=1))\n",
    "            current_channels = out_channels\n",
    "        elif op_name == 'conv5x5':\n",
    "            layers.append(nn.Conv2d(current_channels, out_channels, kernel_size=5, padding=2))\n",
    "            current_channels = out_channels\n",
    "        elif op_name == 'maxpool3x3':\n",
    "            layers.append(nn.MaxPool2d(kernel_size=3, stride=1, padding=1))\n",
    "            # current_channels remains the same\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.AdaptiveAvgPool2d(1))\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(current_channels, 10))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def train_child_network(network, epochs=1):\n",
    "    network.train()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    max_batches = 10  # Limit to 10 batches per epoch\n",
    "    for epoch in range(epochs):\n",
    "        batch_count = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_count += 1\n",
    "            if batch_count >= max_batches:\n",
    "                break  # Stop after processing max_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5: Define the Reinforcement Learning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(controller, controller_optimizer, num_layers, num_operations, num_filters, num_samples):\n",
    "    controller.train()\n",
    "    all_rewards = []\n",
    "    for sample in range(num_samples):\n",
    "        hidden = torch.zeros(1, controller.hidden_size)\n",
    "        cell = torch.zeros(1, controller.hidden_size)\n",
    "        inputs = torch.zeros(1, controller.hidden_size)\n",
    "        architecture = []\n",
    "        log_probs = []\n",
    "        for _ in range(num_layers):\n",
    "            op_logits, filter_logits, hidden, cell = controller(hidden, cell, inputs)\n",
    "            op_probs = F.softmax(op_logits, dim=-1)\n",
    "            filter_probs = F.softmax(filter_logits, dim=-1)\n",
    "            op_dist = torch.distributions.Categorical(op_probs)\n",
    "            filter_dist = torch.distributions.Categorical(filter_probs)\n",
    "            op = op_dist.sample().long()\n",
    "            filter_size = filter_dist.sample().long()\n",
    "            embedding_index = op * controller.num_filters + filter_size\n",
    "            # Print statements for debugging\n",
    "            print(f\"op: {op.item()}, filter_size: {filter_size.item()}\")\n",
    "            print(f\"embedding_index: {embedding_index.item()}, max index: {controller.num_operations * controller.num_filters - 1}\")\n",
    "            # Ensure embedding_index is within bounds\n",
    "            if embedding_index.item() >= controller.num_operations * controller.num_filters:\n",
    "                raise ValueError(f\"embedding_index {embedding_index.item()} out of bounds\")\n",
    "            inputs = controller.embedding(embedding_index)\n",
    "            architecture.append((op.item(), filter_size.item()))\n",
    "            log_probs.append(op_dist.log_prob(op) + filter_dist.log_prob(filter_size))\n",
    "        # ... rest of the code ...\n",
    "\n",
    "        try:\n",
    "            network = construct_network(architecture)\n",
    "            train_child_network(network, epochs=1)\n",
    "            # Evaluate on validation data\n",
    "            network.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in val_loader:\n",
    "                    output = network(data)\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "            reward = correct / total\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred: {e}\")\n",
    "            reward = 0.0\n",
    "        all_rewards.append(reward)\n",
    "        # Policy gradient update\n",
    "        loss = -sum(log_probs) * reward\n",
    "        controller_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        controller_optimizer.step()\n",
    "    return all_rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: Train the Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding layer with num_embeddings = 9\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "Epoch 1/10, Average Reward: 0.1234, Time: 21.10s\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "Epoch 2/10, Average Reward: 0.1418, Time: 27.34s\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "Epoch 3/10, Average Reward: 0.1240, Time: 25.70s\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "Epoch 4/10, Average Reward: 0.1076, Time: 27.17s\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "Epoch 5/10, Average Reward: 0.1084, Time: 23.51s\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "Epoch 6/10, Average Reward: 0.1264, Time: 23.27s\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "Epoch 7/10, Average Reward: 0.1208, Time: 25.66s\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "Epoch 8/10, Average Reward: 0.1152, Time: 23.52s\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "Epoch 9/10, Average Reward: 0.1074, Time: 19.45s\n",
      "op: 2, filter_size: 1\n",
      "embedding_index: 7, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 2, filter_size: 2\n",
      "embedding_index: 8, max index: 8\n",
      "op: 0, filter_size: 0\n",
      "embedding_index: 0, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 2, filter_size: 0\n",
      "embedding_index: 6, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 2\n",
      "embedding_index: 5, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 1, filter_size: 0\n",
      "embedding_index: 3, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 1, filter_size: 1\n",
      "embedding_index: 4, max index: 8\n",
      "op: 0, filter_size: 2\n",
      "embedding_index: 2, max index: 8\n",
      "op: 0, filter_size: 1\n",
      "embedding_index: 1, max index: 8\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 35\n",
    "num_layers = 5\n",
    "OPERATIONS = ['conv3x3', 'conv5x5', 'maxpool3x3']\n",
    "FILTER_SIZES = [16, 32, 64]\n",
    "num_operations = len(OPERATIONS)\n",
    "num_filters = len(FILTER_SIZES)\n",
    "controller = Controller(hidden_size, num_layers, num_operations, num_filters)\n",
    "controller_optimizer = optim.Adam(controller.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "rewards_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    rewards = reinforce(controller, controller_optimizer, num_layers, num_operations, num_filters, num_samples=5)\n",
    "    avg_reward = np.mean(rewards)\n",
    "    rewards_per_epoch.append(avg_reward)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Reward: {avg_reward:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Plotting rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), rewards_per_epoch, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Reward (Validation Accuracy)')\n",
    "plt.title('Controller Training Progress')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7: Evaluate the Best Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "controller.eval()\n",
    "hidden = torch.zeros(1, controller.hidden_size)\n",
    "cell = torch.zeros(1, controller.hidden_size)\n",
    "inputs = torch.zeros(1, 1)\n",
    "architecture = []\n",
    "for _ in range(num_layers):\n",
    "    logits, hidden, cell = controller(hidden, cell, inputs)\n",
    "    _, op = torch.max(logits, dim=-1)\n",
    "    architecture.append(op.item())\n",
    "    inputs = controller.embedding(op).unsqueeze(0)\n",
    "\n",
    "print(\"Best Architecture:\", [OPERATIONS[op] for op in architecture])\n",
    "\n",
    "# Construct and train the best network\n",
    "best_network = construct_network(architecture)\n",
    "train_child_network(best_network, epochs=5)\n",
    "\n",
    "# Evaluate on test data\n",
    "best_network.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = best_network(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy of Best Architecture: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 8: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Placeholder for visualization code, such as plotting rewards over epochs.\n",
    "# In this simplified implementation, we only printed average rewards per epoch.\n",
    "\n",
    "# For example, you might have collected rewards per epoch and can plot them:\n",
    "rewards_per_epoch = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    rewards = reinforce(controller, controller_optimizer, num_layers, num_operations, num_samples=1)\n",
    "    avg_reward = np.mean(rewards)\n",
    "    rewards_per_epoch.append(avg_reward)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Reward: {avg_reward:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Plot the rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs+1), rewards_per_epoch, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Reward (Validation Accuracy)')\n",
    "plt.title('Rewards over Epochs')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
